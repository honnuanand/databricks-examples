{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d92bd39-d934-434e-801e-d9732a6fefb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 02_ADLS_Library_Usage\n",
    "\n",
    "## Importing and Using the Custom Python Library from ADLS Gen2\n",
    "\n",
    "This notebook:\n",
    "‚úÖ Adds the mounted ADLS `libs` path to Python‚Äôs `sys.path`  \n",
    "‚úÖ Imports the custom library (`mylib`)  \n",
    "‚úÖ Calls and tests its functions\n",
    "\n",
    "‚ö† Make sure you‚Äôve run the `01_ADLS_Library_Setup` notebook before this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2640e678-57dd-4e0a-8cd8-30eb77deb689",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Local Setup Before Running the Notebook\n",
    "\n",
    "Before using this notebook, prepare the following on your local machine:\n",
    "\n",
    "‚úÖ Create a simple Python library file named `mylib.py` with this content:\n",
    "\n",
    "```python\n",
    "# mylib.py\n",
    "\n",
    "def greet(name):\n",
    "    return f\"Hello, {name}! Welcome to Databricks.\"\n",
    "\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "def multiply(a, b):\n",
    "    return a * b\n",
    "```\n",
    "\n",
    "- ‚úÖ Copy this file to your local path (example: /tmp/mylib.py or C:\\\\temp\\\\mylib.py).\n",
    "\n",
    "- ‚úÖ Ensure the Databricks Secrets setup (scope: adls-secrets, key: adls-access-key) is ready and that your ADLS container has a libs/ folder for library uploads.\n",
    "\n",
    "- ‚úÖ Make sure Databricks CLI is configured if you plan to upload files via CLI (optional)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff2f206c-d78c-45d6-bd25-7adf5342dfa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Upload the Library File to Databricks\n",
    "\n",
    "You have two options:\n",
    "\n",
    "‚úÖ Option 1 ‚Üí Use the Databricks Data UI\n",
    "\t‚Ä¢\tGo to the Databricks workspace UI (left sidebar ‚Üí Data ‚Üí Upload Data).\n",
    "\t‚Ä¢\tChoose Target Location ‚Üí /tmp/.\n",
    "\t‚Ä¢\tUpload your mylib.py file.\n",
    "\t‚Ä¢\tThis will place the file at: /dbfs/tmp/mylib.py inside the Databricks environment.\n",
    "\n",
    "‚úÖ Option 2 ‚Üí Use the Cell Below to Write the Sample File Directly\n",
    "\t‚Ä¢\tIf you can‚Äôt upload through the UI, use the provided notebook cell that writes the sample file programmatically into /tmp/.\n",
    "\n",
    "‚úÖ Once uploaded (by either method), this notebook will move the file to the ADLS-mounted folder for shared library access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daa252dd-12f0-48dd-a7fe-c44caa36d882",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 141 bytes.\n",
      "‚úÖ Successfully wrote mylib.py to dbfs:/tmp/\n"
     ]
    }
   ],
   "source": [
    "# Write mylib.py into DBFS /tmp using dbutils.fs.put\n",
    "\n",
    "dbutils.fs.put(\"dbfs:/tmp/mylib.py\", \"\"\"\n",
    "def greet(name):\n",
    "    return f\"Hello, {name}! Welcome to Databricks.\"\n",
    "\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "def multiply(a, b):\n",
    "    return a * b\n",
    "\"\"\", overwrite=True)\n",
    "\n",
    "print(\"‚úÖ Successfully wrote mylib.py to dbfs:/tmp/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dc0ab27-cea7-4172-baf2-069fd0634ed3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step üöÄ: Upload `mylib.py` from DBFS `/tmp/` to ADLS `/libs/` Folder\n",
    "\n",
    "This cell performs the following:\n",
    "\n",
    "‚úÖ **Configures Spark** with the storage account key to securely access the ADLS Gen2 container.\n",
    "\n",
    "‚úÖ **Checks if `mylib.py` already exists** in the ADLS `/libs/` folder:\n",
    "- If it exists, it **deletes** the old file to avoid duplicate conflicts.\n",
    "- If it doesn‚Äôt exist, it simply proceeds.\n",
    "\n",
    "‚úÖ **Copies the new `mylib.py` file** from:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Prerequisite: Run 00_Setup Notebook First\n",
    "\n",
    "Before running this notebook, make sure you have completed the setup steps in:\n",
    "\n",
    "`00_Setup and Access-ADLS-Container from the Notebook.ipynb`\n",
    "\n",
    "That notebook walks you through:\n",
    "‚úÖ Creating the Databricks secret scope  \n",
    "‚úÖ Adding the ADLS storage account access key as a secret  \n",
    "‚úÖ Verifying access to the ADLS container\n",
    "\n",
    "Once the setup is done, this notebook will correctly retrieve the secret using:\n",
    "\n",
    "```python\n",
    "dbutils.secrets.get(scope=\"adls-secrets\", key=\"adls-access-key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36f7df66-9c1a-4fa2-aa74-236ecd6c7933",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark config set for ADLS access\n",
      "‚ôªÔ∏è Existing file abfss://araolibraryloadtest@araostorage.dfs.core.usgovcloudapi.net/libs/mylib.py removed\n",
      "‚úÖ Copied mylib.py to abfss://araolibraryloadtest@araostorage.dfs.core.usgovcloudapi.net/libs/mylib.py\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "storage_account = \"araostorage\"\n",
    "container_name = \"araolibraryloadtest\"\n",
    "storage_account_key = dbutils.secrets.get(scope=\"adls-secrets\", key=\"adls-access-key\").strip()\n",
    "adls_libs_path = f\"abfss://{container_name}@{storage_account}.dfs.core.usgovcloudapi.net/libs/mylib.py\"\n",
    "\n",
    "# --- Set Spark Config ---\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{storage_account}.dfs.core.usgovcloudapi.net\",\n",
    "    storage_account_key\n",
    ")\n",
    "print(\"‚úÖ Spark config set for ADLS access\")\n",
    "\n",
    "# --- Check if target file exists ---\n",
    "try:\n",
    "    dbutils.fs.ls(adls_libs_path)\n",
    "    dbutils.fs.rm(adls_libs_path)\n",
    "    print(f\"‚ôªÔ∏è Existing file {adls_libs_path} removed\")\n",
    "except Exception:\n",
    "    print(f\"‚úÖ No existing file at {adls_libs_path}, ready to copy\")\n",
    "\n",
    "# --- Copy file from DBFS /tmp/ to ADLS libs folder ---\n",
    "dbutils.fs.cp(\"dbfs:/tmp/mylib.py\", adls_libs_path)\n",
    "\n",
    "print(f\"‚úÖ Copied mylib.py to {adls_libs_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc2df7e3-9f47-486a-9363-1666644d986f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step üîß: Add ADLS `/libs/` Folder to Python sys.path and Import `mylib`\n",
    "\n",
    "This cell:\n",
    "\n",
    "‚úÖ Maps the ADLS path `/libs/` to a local `/dbfs/` path  \n",
    "‚úÖ Adds that local path to Python‚Äôs `sys.path` so it can import the `mylib` module  \n",
    "‚úÖ Imports `mylib` and runs example function calls to verify everything works\n",
    "\n",
    "‚ö† **Reminder:** Only files inside the `/dbfs/` path are accessible to Python directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d63c199-008f-4038-bb24-69d9a77d7ff0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Copied mylib.py to local DBFS /dbfs/tmp/libs/\n"
     ]
    }
   ],
   "source": [
    "# Copy mylib.py from ADLS to local DBFS path for Python import\n",
    "dbutils.fs.mkdirs(\"dbfs:/tmp/libs\")\n",
    "\n",
    "dbutils.fs.cp(\n",
    "    \"abfss://araolibraryloadtest@araostorage.dfs.core.usgovcloudapi.net/libs/mylib.py\",\n",
    "    \"dbfs:/tmp/libs/mylib.py\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Copied mylib.py to local DBFS /dbfs/tmp/libs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ed19ed3-d596-4516-8afb-cd9ea4cd5170",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ sys.path already includes /dbfs/tmp/libs\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "local_libs_path = \"/dbfs/tmp/libs\"\n",
    "if local_libs_path not in sys.path:\n",
    "    sys.path.append(local_libs_path)\n",
    "    print(f\"‚úÖ Added {local_libs_path} to sys.path\")\n",
    "else:\n",
    "    print(f\"‚úÖ sys.path already includes {local_libs_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b8ca15a-6706-4223-8d18-bd2ee2253b1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Anand! Welcome to Databricks.\n",
      "5 + 7 = 12\n",
      "3 * 4 = 12\n"
     ]
    }
   ],
   "source": [
    "import mylib\n",
    "\n",
    "# Test the functions\n",
    "print(mylib.greet(\"Anand\"))          # Should print: Hello, Anand! Welcome to Databricks.\n",
    "print(f\"5 + 7 = {mylib.add(5, 7)}\") # Should print: 5 + 7 = 12\n",
    "print(f\"3 * 4 = {mylib.multiply(3, 4)}\") # Should print: 3 * 4 = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cd1fa49-d24e-476a-b5f2-7c4d6d4e1e2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- ‚úîÔ∏è You successfully copied your custom mylib.py\n",
    "- ‚úîÔ∏è Added it to the Python path\n",
    "- ‚úîÔ∏è Imported it\n",
    "- ‚úîÔ∏è And ran its functions smoothly inside your Databricks notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "645aaffe-43bb-44b2-8eac-41e3276795a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Option 2: Package and Install a Custom Python Library (`mylib`) on Databricks\n",
    "\n",
    "This section describes how to take a custom Python library, package it as a `.whl`, and install it cleanly inside Databricks notebooks or clusters.\n",
    "\n",
    "---\n",
    "\n",
    "### üìÅ Folder Structure\n",
    "\n",
    "In this repo, under the `/mylib_package/` subfolder (from the provided zip), you will find:\n",
    "```text\n",
    "mylib_package/\n",
    "‚îú‚îÄ‚îÄ mylib/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ core.py\n",
    "‚îú‚îÄ‚îÄ setup.py\n",
    "‚îî‚îÄ‚îÄ README.md\n",
    "```\n",
    "\n",
    "- `core.py` ‚Üí Contains the main functions (`greet`, `add`, `multiply`)  \n",
    "- `__init__.py` ‚Üí Makes the module importable  \n",
    "- `setup.py` ‚Üí Defines the package metadata and build instructions\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Steps to Build and Use\n",
    "\n",
    "1Ô∏è‚É£ **On Your Local Machine**\n",
    "- Navigate into the `mylib_package/` folder.\n",
    "- Run:\n",
    "    ```bash\n",
    "    pip install --upgrade setuptools wheel\n",
    "    python setup.py bdist_wheel\n",
    "    ```\n",
    "- This creates a `.whl` file under `dist/`:\n",
    "    ```\n",
    "    dist/mylib-0.1-py3-none-any.whl\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "2Ô∏è‚É£ **Upload to Databricks**\n",
    "- Use the Databricks CLI or UI to upload:\n",
    "    ```\n",
    "    dist/mylib-0.1-py3-none-any.whl ‚Üí dbfs:/tmp/mylib-0.1-py3-none-any.whl\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "3Ô∏è‚É£ **Install in Notebook**\n",
    "- In a Databricks notebook, run:\n",
    "    ```python\n",
    "    %pip install /dbfs/tmp/mylib-0.1-py3-none-any.whl\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "4Ô∏è‚É£ **Restart the Python Kernel**\n",
    "- After installing, restart the notebook kernel:\n",
    "    ```python\n",
    "    %restart_python\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "5Ô∏è‚É£ **Import and Use**\n",
    "- In the notebook, import and test the library:\n",
    "    ```python\n",
    "    import mylib\n",
    "\n",
    "    print(mylib.greet(\"Anand\"))\n",
    "    print(f\"5 + 7 = {mylib.add(5, 7)}\")\n",
    "    print(f\"3 * 4 = {mylib.multiply(3, 4)}\")\n",
    "    ```\n",
    "\n",
    "‚úÖ This ensures your custom code runs as a proper, installable Python package inside Databricks.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Notes\n",
    "\n",
    "- To make the library **available cluster-wide**, you can upload the `.whl` through **Workspace ‚Üí Libraries ‚Üí Install New ‚Üí Upload** and attach it at the cluster level.\n",
    "- For versioning, update the `version=` field in `setup.py` before rebuilding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09318ee3-8070-4d5c-9bf7-b40baf501aa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /dbfs/tmp/mylib-0.1-py3-none-any.whl\n",
      "mylib is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install /dbfs/tmp/mylib-0.1-py3-none-any.whl\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8c29084-577a-4be5-96f3-82febf413589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Anand! Welcome to Databricks.\n",
      "5 + 7 = 12\n",
      "3 * 4 = 12\n"
     ]
    }
   ],
   "source": [
    "import mylib\n",
    "\n",
    "print(mylib.greet(\"Anand\"))\n",
    "print(f\"5 + 7 = {mylib.add(5, 7)}\")\n",
    "print(f\"3 * 4 = {mylib.multiply(3, 4)}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_ADLS_Library_Usage",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
